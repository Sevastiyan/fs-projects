{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the applet:\n",
    "\n",
    "- First we need to select the data from the server in a new csv file with all the data we need. \n",
    "    - sessio_number\n",
    "    - rawDataLeft\n",
    "    - rawDataRight\n",
    "    - created\n",
    "- These will help out when selecting the data on back4app\n",
    "- Then we export the csv file and we put it within the folder of this app.\n",
    "- The next step is to make a json file using the `make_json(file_to_read, file_to_make)`\n",
    "- After the json file is made (we can actually keep it in memory by returning the dictionary) we read the file\n",
    "- We then extract the urls (read the json file for more info)\n",
    "- Then using the urls we can download the data\n",
    "- Last piece is to rename the files in the correct format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to read json file\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "# Request url info\n",
    "import requests  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(url_list, download_path):\n",
    "    '''\n",
    "    Download files into provided pathway given a list of url\n",
    "\n",
    "    @Params:\n",
    "    url_list (list) - List of url to download from\n",
    "    download_path (str) - path to download the files into\n",
    "\n",
    "    Does not have return values\n",
    "    '''\n",
    "\n",
    "    # Save text from url as a .txt\n",
    "    for url in url_list:\n",
    "        f = requests.get(url)\n",
    "        \n",
    "        # filename gotten by splitting url and removing the unique ID of each dataset\n",
    "        filename = url.split('/')[-1][33:-4] + '.txt'\n",
    "\n",
    "        # Save files as txt\n",
    "        with open(download_path + filename, \"w+\") as text_file:\n",
    "            text_file.write(f.text)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def make_json(csvFilePath, jsonFilePath):\n",
    "    # create a dictionary\n",
    "    data = {}\n",
    "    # Open a csv reader called DictReader\n",
    "    with open(csvFilePath, encoding='utf-8') as csvf:\n",
    "        csvReader = csv.DictReader(csvf)\n",
    "        # Convert each row into a dictionary\n",
    "        # and add it to data\n",
    "        for rows in csvReader:\n",
    "            # Assuming a column named 'No' to\n",
    "            # be the primary key\n",
    "            key = rows['sessionNumber']\n",
    "            data[key] = rows\n",
    "            data[key]['rawDataLeft'] = json.loads(rows['rawDataLeft'])\n",
    "            data[key]['rawDataRight'] = json.loads(rows['rawDataRight'])\n",
    "    # Open a json writer, and use the json.dumps()\n",
    "    # function to dump data\n",
    "    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf:\n",
    "        jsonf.write(json.dumps(data, indent=4))\n",
    "\n",
    "\n",
    "def read_json(jsonFilePath):\n",
    "    with open(jsonFilePath, \"r\") as read_it:\n",
    "        data = json.load(read_it)\n",
    "\n",
    "    return data\n",
    "\n",
    "    \n",
    "def rename_files(path):\n",
    "    print(path)\n",
    "    files = os.listdir(path)  # List of files in the data path folder\n",
    "    for file in files:\n",
    "        filename = file.split(\".txt\")[0]\n",
    "        str_list = filename.split(\"_\")\n",
    "        new_filename = str_list[2] + \"_\" + str_list[3] + \"_\" + str_list[1] + \"_\" + str_list[0] + \".txt\"\n",
    "        os.rename(os.path.join(path, file), os.path.join(path, new_filename))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_json('Recent json file/RawDataFiles.csv', 'result.json')\n",
    "data = read_json('result.json')\n",
    "\n",
    "urls = []\n",
    "for d in data.values():\n",
    "    urls.append(d['rawDataLeft']['url']) \n",
    "    urls.append(d['rawDataRight']['url'])\n",
    "\n",
    "download_path = 'download/'\n",
    "download_files(urls, download_path)\n",
    "rename_files('download')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF29_PY39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8ccd1f78b08338c56d6315dbbc03b22ce55e31fb67884ce372769d8a6478d62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
