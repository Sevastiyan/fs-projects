{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the applet:\n",
    "\n",
    "- First we need to select the data from the server in a new csv file with all the data we need. \n",
    "    - sessio_number\n",
    "    - rawDataLeft\n",
    "    - rawDataRight\n",
    "    - created\n",
    "- These will help out when selecting the data on back4app\n",
    "- Then we export the csv file and we put it within the folder of this app.\n",
    "- The next step is to make a json file using the `make_json(file_to_read, file_to_make)`\n",
    "- After the json file is made (we can actually keep it in memory by returning the dictionary) we read the file\n",
    "- We then extract the urls (read the json file for more info)\n",
    "- Then using the urls we can download the data\n",
    "- Last piece is to rename the files in the correct format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to read json file\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "# Request url info\n",
    "import requests  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\yang\\\\Documents\\\\GitHub\\\\fs-projects\\\\Extract data from database'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(url_list, download_path):\n",
    "    '''\n",
    "    Download files into provided pathway given a list of url\n",
    "\n",
    "    @Params:\n",
    "    url_list (list) - List of url to download from\n",
    "    download_path (str) - path to download the files into\n",
    "\n",
    "    Does not have return values\n",
    "    '''\n",
    "\n",
    "    # Save text from url as a .txt\n",
    "    \n",
    "    if not os.path.exists(download_path):\n",
    "        os.makedirs(download_path)\n",
    "    \n",
    "    for url in url_list:\n",
    "        f = requests.get(url)\n",
    "        \n",
    "        # filename gotten by splitting url and removing the unique ID of each dataset\n",
    "        filename = url.split('/')[-1][33:-4] + '.txt'\n",
    "\n",
    "        # Save files as txt\n",
    "        with open(download_path + filename, \"w+\") as text_file:\n",
    "            text_file.write(f.text)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def make_json(csvFilePath: str, jsonFilePath: str) -> str:\n",
    "    # create a dictionary\n",
    "    data = {}\n",
    "    # Open a csv reader called DictReader\n",
    "    \n",
    "    with open(csvFilePath, encoding='utf-8') as csvf:\n",
    "        csvReader = csv.DictReader(csvf)\n",
    "        # Convert each row into a dictionary\n",
    "        # and add it to data\n",
    "        for rows in csvReader:\n",
    "            # Assuming a column named 'No' to\n",
    "            # be the primary key\n",
    "            key = rows['sessionNumber']\n",
    "            data[key] = rows\n",
    "            data[key]['rawDataLeft'] = json.loads(rows['rawDataLeft'])\n",
    "            data[key]['rawDataRight'] = json.loads(rows['rawDataRight'])\n",
    "    # Open a json writer, and use the json.dumps()\n",
    "    # function to dump data\n",
    "    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf:\n",
    "        jsonf.write(json.dumps(data, indent=4))\n",
    "    \n",
    "    return jsonFilePath\n",
    "\n",
    "\n",
    "def read_json(jsonFilePath):\n",
    "    with open(jsonFilePath, \"r\") as read_it:\n",
    "        data = json.load(read_it)\n",
    "\n",
    "    return data\n",
    "\n",
    "    \n",
    "def rename_files(path):\n",
    "    print(path)\n",
    "    files = os.listdir(path)  # List of files in the data path folder\n",
    "    for file in files:\n",
    "        filename = file.split(\".txt\")[0]\n",
    "        str_list = filename.split(\"_\")\n",
    "        new_filename = str_list[2] + \"_\" + str_list[3] + \"_\" + str_list[1] + \"_\" + str_list[0] + \".txt\"\n",
    "        os.rename(os.path.join(path, file), os.path.join(path, new_filename))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './csv/2023-06-29 flexosensemci004 Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m root_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#'./Extract data from database'\u001b[39;00m\n\u001b[0;32m      3\u001b[0m date \u001b[38;5;241m=\u001b[39m root_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m json_file \u001b[38;5;241m=\u001b[39m \u001b[43mmake_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mroot_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/csv/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mroot_file\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mroot_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/json/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mroot_file\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m read_json(json_file)\n\u001b[0;32m      8\u001b[0m urls \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[3], line 35\u001b[0m, in \u001b[0;36mmake_json\u001b[1;34m(csvFilePath, jsonFilePath)\u001b[0m\n\u001b[0;32m     32\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Open a csv reader called DictReader\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsvFilePath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csvf:\n\u001b[0;32m     36\u001b[0m     csvReader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(csvf)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Convert each row into a dictionary\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# and add it to data\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './csv/2023-06-29 flexosensemci004 Data.csv'"
     ]
    }
   ],
   "source": [
    "root_file = '2023-06-29 flexosensemci004 Data'\n",
    "root_folder = '.' #'./Extract data from database'\n",
    "date = root_file.split(' ')[0]\n",
    "\n",
    "json_file = make_json(f'{root_folder}/csv/{root_file}.csv', f'{root_folder}/json/{root_file}.json')\n",
    "data = read_json(json_file)\n",
    "\n",
    "urls = []\n",
    "for d in data.values():\n",
    "    urls.append(d['rawDataLeft']['url']) \n",
    "    urls.append(d['rawDataRight']['url'])\n",
    "\n",
    "download_path = f'download/{date}/{root_file}/'\n",
    "download_files(urls, download_path)\n",
    "rename_files(download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\joonn\\\\Desktop\\\\pyscript\\\\Extract data from database'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF29_PY39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8ccd1f78b08338c56d6315dbbc03b22ce55e31fb67884ce372769d8a6478d62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
