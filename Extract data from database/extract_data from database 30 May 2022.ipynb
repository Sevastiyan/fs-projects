{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to read json file\n",
    "import json\n",
    "\n",
    "# Request url info\n",
    "import requests  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This program assumes that the json file has been downloaded from the backend. \n",
    "Back4App JSON export contains all rows and is not filtered as compared to CSV format.\n",
    "(CSV export does not contain url for download hence using JSON)\n",
    "'''\n",
    "\n",
    "# Opening JSON file\n",
    "f = open('json file\\RawDataFiles.json')\n",
    "  \n",
    "# returns JSON object as a dictionary\n",
    "full_data = json.load(f)\n",
    "  \n",
    "# Closing file\n",
    "f.close()\n",
    "\n",
    "# Iterating through the json list (For Double Checking)\n",
    "# for i in full_data['results']:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_session_from_database(full_data, userPointer, start_session, end_session):\n",
    "    '''\n",
    "    Extracting database info user of interest\n",
    "\n",
    "    @Params:\n",
    "    userPointer (str) - B4A user account to extract from\n",
    "    start_session (int) - User session number to extract from\n",
    "    end_session (int) - User session number to extract from\n",
    "    '''\n",
    "\n",
    "    data = []\n",
    "    # Filter full JSON file to a list of dictionaries without 'results' key\n",
    "    for i in range(len(full_data['results'])):\n",
    "        if (full_data['results'][i]['userPointer']['objectId'] == userPointer) and (start_session <= full_data['results'][i]['sessionNumber'] <= end_session):\n",
    "            data.append(full_data['results'][i])\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_url(data):\n",
    "    '''\n",
    "    Extract url field from database info\n",
    "\n",
    "    Params:\n",
    "    data - data rows of user of interest\n",
    "\n",
    "    Returns a list of url\n",
    "\n",
    "    '''\n",
    "\n",
    "    url_list = []\n",
    "    # Append url of data in list to prepare for download\n",
    "    for i in range(len(data)):\n",
    "        url_list.append(data[i]['rawDataLeft']['url'])\n",
    "        url_list.append(data[i]['rawDataRight']['url'])\n",
    "\n",
    "    return url_list\n",
    "\n",
    "def download_files(url_list, download_path):\n",
    "    '''\n",
    "    Download files into provided pathway given a list of url\n",
    "\n",
    "    @Params:\n",
    "    url_list (list) - List of url to download from\n",
    "    download_path (str) - path to download the files into\n",
    "\n",
    "    Does not have return values\n",
    "    '''\n",
    "\n",
    "    # Save text from url as a .txt\n",
    "    for url in url_list:\n",
    "        f = requests.get(url)\n",
    "        \n",
    "        # filename gotten by splitting url and removing the unique ID of each dataset\n",
    "        filename = url.split('/')[-1][33:-4] + '.txt'\n",
    "\n",
    "        # Save files as txt\n",
    "        with open(download_path + filename, \"w+\") as text_file:\n",
    "            text_file.write(f.text)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variables here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "userPointer = 'pJcKIuG40k'\n",
    "start_session = 63\n",
    "end_session = 87\n",
    "\n",
    "# Insert full directory, include '/' at the end to prevent directory misname\n",
    "download_path = 'C:/Users/bendy/Desktop/Ben/!! Summary of ipynb (Most updated)/Extract data from database/downloaded_files/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Program here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extract_session_from_database(full_data, userPointer, start_session,end_session)\n",
    "url_list = extract_url(data)\n",
    "download_files(url_list, download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double checking number of data received and files downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of session is: 25\n",
      "Total length in url_list is: 50 (Supposed to be twice of sessions)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of session is: {len(data)}\")\n",
    "print(f\"Total length in url_list is: {len(url_list)} (Supposed to be twice of sessions)\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
